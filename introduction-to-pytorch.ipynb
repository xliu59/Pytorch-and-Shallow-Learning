{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.0000e+00  0.0000e+00  4.4793e-29\n",
      " 2.5244e-29  5.6052e-45  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  2.6806e-29 -1.0842e-19\n",
      " 2.2335e+08  2.2369e+08  5.4991e-39\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct a 5x3 matrix, uninitialized:\n",
    "x = torch.Tensor(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.1261  0.4473  0.5235\n",
      " 0.3710  0.7736  0.7357\n",
      " 0.8386  0.7023  0.3916\n",
      " 0.4871  0.1715  0.1443\n",
      " 0.0109  0.3018  0.0289\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct a randomly initialized matrix\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# Get its size\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.6647  0.9291  1.1376\n",
      " 0.8830  1.4320  1.4977\n",
      " 1.4774  1.0950  0.6185\n",
      " 1.2637  1.0200  1.0381\n",
      " 0.2512  1.0105  0.6091\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Addition : syntax 1\n",
    "y = torch.rand(5, 3)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.6647  0.9291  1.1376\n",
      " 0.8830  1.4320  1.4977\n",
      " 1.4774  1.0950  0.6185\n",
      " 1.2637  1.0200  1.0381\n",
      " 0.2512  1.0105  0.6091\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Addition : syntax 2\n",
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.6647  0.9291  1.1376\n",
      " 0.8830  1.4320  1.4977\n",
      " 1.4774  1.0950  0.6185\n",
      " 1.2637  1.0200  1.0381\n",
      " 0.2512  1.0105  0.6091\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Addition: giving an output tensor\n",
    "result = torch.Tensor(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.1261  0.4473  0.5235\n",
      " 0.3710  0.7736  0.7357\n",
      " 0.8386  0.7023  0.3916\n",
      " 0.4871  0.1715  0.1443\n",
      " 0.0109  0.3018  0.0289\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Addition: in-place\n",
    "y.add_(x) # equals to y = y.add(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.4473\n",
      " 0.7736\n",
      " 0.7023\n",
      " 0.1715\n",
      " 0.3018\n",
      "[torch.FloatTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# supports numpy-like indexing\n",
    "print(x[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy Bridge\n",
    "- Supports converting a torch Tensor to a numpy array and vice versa.\n",
    "- The torch Tensor and numpy array will share their underlying memory locations, and changing one will change the other.\n",
    "- All the Tensors on the CPU except a CharTensor support converting to NumPy and back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting torch Tensor to numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "<class 'torch.FloatTensor'>\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "[ 2.  2.  2.  2.  2.]\n"
     ]
    }
   ],
   "source": [
    "# See how the numpy array changed in value.\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting numpy Array to torch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  2.  2.  2.  2.]\n",
      "\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.DoubleTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a) #convert\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    x + y\n",
    "    print(\"yes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd: automatic differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1  1\n",
      " 1  1\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Variable containing:\n",
      "-2\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "[1]\n",
      "here\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "<torch.autograd.function.MulConstantBackward object at 0x106899138>\n"
     ]
    }
   ],
   "source": [
    "# Create a variable:\n",
    "x = Variable(torch.ones(2, 2), requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "m = Variable(torch.Tensor([1,2,1]))\n",
    "n = Variable(torch.Tensor([2,0,1]))\n",
    "s = n[0]\n",
    "s = s * -1\n",
    "print(s)\n",
    "print((s.data < 0).numpy())\n",
    "print(\"here\")\n",
    "# zero= Variable(torch.FloatTensor([0]))\n",
    "# print(zero)\n",
    "# print(\"aaa\")\n",
    "torch.max(Variable(torch.FloatTensor([0])), s)\n",
    "loss = torch.max(Variable(torch.FloatTensor([0])), s * -1)\n",
    "print(loss)\n",
    "print(s.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 3  3\n",
      " 3  3\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Do an operation of variable:\n",
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.autograd.function.AddConstantBackward object at 0x106899408>\n"
     ]
    }
   ],
   "source": [
    "# y was created as a result of an operation, so it has a grad_fn.\n",
    "# the .grad_fn attribute that references a Function that has created the Variable (except for Variables created by the user - their grad_fn is None\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 27  27\n",
      " 27  27\n",
      "[torch.FloatTensor of size 2x2]\n",
      " Variable containing:\n",
      " 27\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# do more operations on y\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 4.5000  4.5000\n",
      " 4.5000  4.5000\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print gradients d(out)/dx\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.2949\n",
      " 0.6096\n",
      " 2.4586\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      "  150.9858\n",
      "  312.0999\n",
      " 1258.7950\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# another example\n",
    "x = torch.randn(3)\n",
    "print(x)\n",
    "x = Variable(x, requires_grad=True)\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "  51.2000\n",
      " 512.0000\n",
      "   0.0512\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "varibale.backward()\n",
    "        Computes the gradient of current variable w.r.t. graph leaves.\n",
    "        The graph is differentiated using the chain rule. If the variable is\n",
    "        non-scalar (i.e. its data has more than one element) and requires\n",
    "        gradient, the function additionally requires specifying ``gradient``.\n",
    "        It should be a tensor of matching type and location, that contains\n",
    "        the gradient of the differentiated function w.r.t. ``self``.   ???\n",
    "\"\"\"\n",
    "\n",
    "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
    "y.backward(gradients)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical training procedure for a neural network is as follows:\n",
    "- Define the neural network that has some learnable parameters (or weights)\n",
    "- Iterate over a dataset of inputs\n",
    "- Process input through the network\n",
    "- Compute the loss (how far is the output from being correct)\n",
    "- Propagate gradients back into the network’s parameters\n",
    "- Update the weights of the network, typically using a simple update rule:\n",
    "        weight = weight - learning_rate * gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> a sample netwrok structure:\n",
    "![title](./img1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the (above) network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net (\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear (400 -> 120)\n",
      "  (fc2): Linear (120 -> 84)\n",
      "  (fc3): Linear (84 -> 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution / kernel / filter / neuron\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, input): # must define for a nn, tells about the structure\n",
    "        \"\"\"\n",
    "        We just have to define the forward function, \n",
    "        and the backward function (where gradients are computed) \n",
    "        is automatically defined for you using autograd. \n",
    "        You can use any of the Tensor operations in the forward function.\n",
    "        \n",
    "        The input to the forward is an autograd.Variable, and so is the output. \n",
    "        Note: Expected input size to this net(LeNet) is 32x32.\n",
    "        \"\"\"\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(input)), (2, 2)) # first convolve the input, \n",
    "                                                            # then use relu as activation function\n",
    "                                                            # then use max pooling (2*2 widow)\n",
    "                                                            # output is x\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)          # use the previous output and continue feed forward\n",
    "        x = x.view(-1, self.num_flat_features(x)) # view returns a new tensor with the same data but different size\n",
    "                                                  # the size -1 is inferred from other dimensions (the ret value \n",
    "                                                  # of self.num_flat_features() here)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)   # why last layer has no activation??\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension ??\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([16, 6, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([120, 400])\n",
      "torch.Size([120])\n",
      "torch.Size([84, 120])\n",
      "torch.Size([84])\n",
      "torch.Size([10, 84])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# The learnable parameters of a model are returned by net.parameters()\n",
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size()) # conv1's .weight\n",
    "print(params[1].size()) # activation function ???\n",
    "print(params[2].size()) # conv2's .weight\n",
    "print(params[3].size()) # ???\n",
    "print(params[4].size()) # fc1's .weight\n",
    "print(params[5].size()) # ???\n",
    "print(params[6].size()) # fc2's .weight\n",
    "print(params[7].size()) # ???\n",
    "print(params[8].size()) # fc3's .weight\n",
    "print(params[9].size()) # ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: \n",
    "torch.nn only supports mini-batches The entire torch.nn package only supports inputs that are a mini-batch of samples, and not a single sample.\n",
    "\n",
    "> For example, nn.Conv2d will take in a 4D Tensor of nSamples x nChannels x Height x Width.\n",
    "If you have a single sample, just use input.unsqueeze(0) to add a fake batch dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.0529 -0.1147  0.0262  0.0703  0.0176  0.0454  0.1209  0.0697 -0.1135 -0.0394\n",
      "[torch.FloatTensor of size 1x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Expected input size to this net(LeNet) is 32x32. \n",
    "# To use this net on MNIST dataset, please resize \n",
    "# the images from the dataset to 32x32.\n",
    "input = Variable(torch.randn(1, 1, 32, 32)) # a 4D Tensor of nSamples x nChannels x Height x Width.\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Zero the gradient buffers of all parameters and backprops with random gradients\n",
    "net.zero_grad()\n",
    "# call backward\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "- A loss function takes the (output, target) pair of inputs, and computes a value that estimates how far away the output is from the target.\n",
    "- There are several different loss functions under the nn package . A simple loss is: nn.MSELoss which computes the mean-squared error between the input and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 38.8918\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# nn.MSELoss example\n",
    "input = Variable(torch.randn(1, 1, 32, 32))\n",
    "output = net(input)\n",
    "target = Variable(torch.arange(1, 11))  # arange: Returns a 1D Tensor of size \n",
    "                                        # floor((end−start)/step)floor((end−start)/step) \n",
    "                                        # with values from the interval [start, end) \n",
    "                                        # taken with step step starting from start.\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(out, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So, when we call loss.backward(), the whole graph is differentiated w.r.t. the loss, and all Variables in the graph will have their .grad Variable accumulated with the gradient.\n",
    "- The graph of computations of above net is as below:\n",
    "    \n",
    "    \n",
    "   \n",
    "    input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n",
    "          -> view -> linear -> relu -> linear -> relu -> linear\n",
    "          -> MSELoss\n",
    "          -> loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.autograd.function.MSELossBackward object at 0x109d036d8>\n",
      "<torch.autograd.function.AddmmBackward object at 0x109d035e8>\n",
      "<AccumulateGrad object at 0x109b5d908>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn) #MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0]) # linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0]) # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprop\n",
    "- Before use loss.backward(), we need to clear the existing gradients, otherwise gradients will be accumulated to existing gradients \n",
    "- (this should be done for every traning example (or batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 6]\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-730019afede6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# what is .bias?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conv1.bias.grad after backward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/torch/autograd/_functions/blas.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mmatrix1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mgrad_add_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_matrix1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_matrix2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "net.zero_grad()\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad) # what is .bias?\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the weights\n",
    "- The simplest update rule used in practice is the Stochastic Gradient Descent (SGD):\n",
    "\n",
    "        weight = weight - learning_rate * gradient\n",
    "- To use other different update rules such as SGD, Nesterov-SGD, Adam, RMSProp, etc. To enable this, use the official package: <font color='red'>**torch.optim**</font> that implements all these methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# example SGD update:\n",
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate) # what is sub_; f.data???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# example of torch.optim\n",
    "import torch.optim as optim\n",
    "\n",
    "# create the optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad() # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step() # Does the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deal with image, text, audio or video data, you can use standard python packages that load data into a numpy.  Then you can convert this array into a **torch.*Tensor** array\n",
    "- For images, packages such as torchVision, Pillow, OpenCV are useful.\n",
    "    - torchvision has data loaders for common datasets such as Imagenet, CIFAR10, MNIST, etc. and data transformers for images, viz., torchvision.datasets and torch.utils.data.DataLoade\n",
    "- For audio, packages such as scipy and librosa\n",
    "- For text, either raw Python or Cython based loading, or NLTK and SpaCy are useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an image classifier\n",
    "steps:\n",
    "- Load and normalizing the CIFAR10 training and test datasets using torchvision\n",
    "- Define a Convolution Neural Network\n",
    "- Define a loss function\n",
    "- Train the network on the training data\n",
    "- Test the network on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading and normalizing CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# The output of torchvision datasets are PILImage images of range [0, 1]. \n",
    "# We transform them to Tensors of normalized range [-1, 1]  ???\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109ad2208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  car horse   cat   car\n"
     ]
    }
   ],
   "source": [
    "# show some of the training images\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "# print(labels)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "plt.show()\n",
    "\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Copy from previous example with some modification\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution / kernel / filter / neuron\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) # change input channel to 3\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # define only one is enought, since the two pooling layers are the same\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, input): # must define for a nn, tells about the structure\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = self.pool(F.relu(self.conv1(input))) # use defined pool module instead of F.max_pool2d(.., 2)\n",
    "        x = self.pool(F.relu(self.conv2(x))) \n",
    "        x = x.view(-1, 16 * 5 * 5) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)   \n",
    "        return x\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use classification Cross-Entropy loss and SGD with momentum --???\n",
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss : 2.190\n",
      "[1,  4000] loss : 1.854\n",
      "[1,  6000] loss : 1.651\n",
      "[1,  8000] loss : 1.563\n",
      "[1, 10000] loss : 1.526\n",
      "[1, 12000] loss : 1.478\n",
      "[2,  2000] loss : 1.397\n",
      "[2,  4000] loss : 1.382\n",
      "[2,  6000] loss : 1.352\n",
      "[2,  8000] loss : 1.299\n",
      "[2, 10000] loss : 1.313\n",
      "[2, 12000] loss : 1.290\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# loop over our data iterator, and feed the inputs to the network and optimize\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:   # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss : %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test the network on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nu0MvjO8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a04eda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradTruth(/true label):    cat  ship  ship plane\n"
     ]
    }
   ],
   "source": [
    "# first step. Let us display an image from the test set to get familiar.\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "plt.show()\n",
    "print('GradTruth(/true label): ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now lets used the trained nn to predict labels\n",
    "outputs = net(Variable(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note : The outputs are energies for the 10 classes. Higher the energy for a class, the more the network thinks that the image is of the particular class. So, let’s get the index of the highest energy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:    cat  ship plane  ship\n"
     ]
    }
   ],
   "source": [
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 56 %\n"
     ]
    }
   ],
   "source": [
    "# test on the whole dataset\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "# if randomly picking a class out of 10 classes, the approximate accuracy will be 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 67 %\n",
      "Accuracy of   car : 60 %\n",
      "Accuracy of  bird : 42 %\n",
      "Accuracy of   cat : 29 %\n",
      "Accuracy of  deer : 56 %\n",
      "Accuracy of   dog : 38 %\n",
      "Accuracy of  frog : 71 %\n",
      "Accuracy of horse : 66 %\n",
      "Accuracy of  ship : 65 %\n",
      "Accuracy of truck : 68 %\n"
     ]
    }
   ],
   "source": [
    "# To know what are the classes that performed well, and the classes that did not perform well:\n",
    "class_correct = list(0. for i in range(10))  # [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "class_total = list(0. for i in range(10))\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(4):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-274-6fd1e0bd34f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \"\"\"\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may cause AssertionError if cuda is not available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Baltimore/Homework/Machine_Learning/Project1/Pytorch-and-Shallow-Learning/python3-proj1/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device_id)\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0mcopied\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Baltimore/Homework/Machine_Learning/Project1/Pytorch-and-Shallow-Learning/python3-proj1/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Baltimore/Homework/Machine_Learning/Project1/Pytorch-and-Shallow-Learning/python3-proj1/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0;31m# Variables stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Baltimore/Homework/Machine_Learning/Project1/Pytorch-and-Shallow-Learning/python3-proj1/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0mcopied\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Baltimore/Homework/Machine_Learning/Project1/Pytorch-and-Shallow-Learning/python3-proj1/lib/python3.5/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Baltimore/Homework/Machine_Learning/Project1/Pytorch-and-Shallow-Learning/python3-proj1/lib/python3.5/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_new\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_lazy_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0;31m# We need this method only for lazy init, so we can remove it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0m_CudaBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Baltimore/Homework/Machine_Learning/Project1/Pytorch-and-Shallow-Learning/python3-proj1/lib/python3.5/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m         raise RuntimeError(\n\u001b[1;32m     83\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_sparse_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Baltimore/Homework/Machine_Learning/Project1/Pytorch-and-Shallow-Learning/python3-proj1/lib/python3.5/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Just like how you transfer a Tensor on to the GPU, \n",
    "you transfer the neural net onto the GPU. \n",
    "This will recursively go over all modules and \n",
    "convert their parameters and buffers to CUDA tensors:\n",
    "\"\"\"\n",
    "\n",
    "net.cuda()  # may cause AssertionError if cuda is not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-275-e39a621f4eb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mRemember\u001b[0m \u001b[0mthat\u001b[0m \u001b[0myou\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mto\u001b[0m \u001b[0msend\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0mat\u001b[0m \u001b[0mevery\u001b[0m \u001b[0mstep\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mGPU\u001b[0m \u001b[0mtoo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# may cause AssertionError if cuda is not available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Baltimore/Homework/Machine_Learning/Project1/Pytorch-and-Shallow-Learning/python3-proj1/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device_id, async)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCudaTransfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Baltimore/Homework/Machine_Learning/Project1/Pytorch-and-Shallow-Learning/python3-proj1/lib/python3.5/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, device_id, async)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Baltimore/Homework/Machine_Learning/Project1/Pytorch-and-Shallow-Learning/python3-proj1/lib/python3.5/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Baltimore/Homework/Machine_Learning/Project1/Pytorch-and-Shallow-Learning/python3-proj1/lib/python3.5/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_new\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_lazy_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0;31m# We need this method only for lazy init, so we can remove it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0m_CudaBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Baltimore/Homework/Machine_Learning/Project1/Pytorch-and-Shallow-Learning/python3-proj1/lib/python3.5/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m         raise RuntimeError(\n\u001b[1;32m     83\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_sparse_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Baltimore/Homework/Machine_Learning/Project1/Pytorch-and-Shallow-Learning/python3-proj1/lib/python3.5/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Remember that you will have to send the inputs and targets at every step to the GPU too:\n",
    "\"\"\"\n",
    "inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda()) # may cause AssertionError if cuda is not available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn package (Not for homework)\n",
    "- torch.nn only supports mini-batches The entire torch.nn package only supports inputs that are a mini-batch of samples, and not a single sample.\n",
    "- For example, nn.Conv2d will take in a 4D Tensor of nSamples x nChannels x Height x Width.\n",
    "- If you have a single sample, just use input.unsqueeze(0) to add a fake batch dimension.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MNISTConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # this is the place where you instantiate all your modules\n",
    "        # you can later access them using the same names you've given them in\n",
    "        # here\n",
    "        super(MNISTConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(320, 50) # fully connected layer1\n",
    "        self.fc2 = nn.Linear(50, 10) # fully connected layer2\n",
    "    \n",
    "    # it's the forward function that defines the network structure\n",
    "    # we're accepting only a single input in here, but if you want,\n",
    "    # feel free to use more\n",
    "    def forward(self, input):\n",
    "        x = self.pool1(F.relu(self.conv1(input)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        # in your model definition you can go full crazy and use arbitrary\n",
    "        # python code to define your model structure\n",
    "        # all these are perfectly legal, and will be handled correctly\n",
    "        # by autograd:\n",
    "        # if x.gt(0) > x.numel() / 2:\n",
    "        #      ...\n",
    "        #\n",
    "        # you can even do a loop and reuse the same module inside it\n",
    "        # modules no longer hold ephemeral state, so you can use them\n",
    "        # multiple times during your forward pass\n",
    "        # while x.norm(2) < 10:\n",
    "        #    x = self.conv1(x)\n",
    "        x = x.view(x.size(0), -1)  # ???\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTConvNet (\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (fc1): Linear (320 -> 50)\n",
      "  (fc2): Linear (50 -> 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# use the defined ConvNet, create an instance of the class first\n",
    "net = MNISTConvNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# Create a mini-batch containing a single sample of random data and send the sample through the ConvNet.\n",
    "input = Variable(torch.randn(1, 1, 28, 28))  # ???\n",
    "out = net(input)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 2.3967\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a dummy target label and compute error using a loss function\n",
    "target = Variable(torch.LongTensor([3]))\n",
    "loss_fn = nn.CrossEntropyLoss() # LogSoftmax + ClassNLL Loss ???\n",
    "err = loss_fn(out, target)\n",
    "err.backward()\n",
    "\"\"\"\n",
    "The output of the ConvNet out is a Variable. We compute the loss using that, \n",
    "and that results in err which is also a Variable. Calling .backward on err \n",
    "hence will propagate gradients all the way through the ConvNet to it’s weights\n",
    "\"\"\"\n",
    "\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "# access individual layer weights and gradients\n",
    "print(net.conv1.weight.grad.size())  # ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8969228834585605\n",
      "0.4444073020985585\n"
     ]
    }
   ],
   "source": [
    "print(net.conv1.weight.data.norm())  # norm of the weight\n",
    "print(net.conv1.weight.grad.data.norm())  # norm of the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Conv2d forward\n",
      "\n",
      "input:  <class 'tuple'>\n",
      "input[0]:  <class 'torch.autograd.variable.Variable'>\n",
      "output:  <class 'torch.autograd.variable.Variable'>\n",
      "\n",
      "input size:  torch.Size([1, 10, 12, 12])\n",
      "output size:  torch.Size([1, 20, 8, 8])\n",
      "output norm:  13.748090078970105\n",
      "Inside Conv2d forward\n",
      "\n",
      "input:  <class 'tuple'>\n",
      "input[0]:  <class 'torch.autograd.variable.Variable'>\n",
      "output:  <class 'torch.autograd.variable.Variable'>\n",
      "\n",
      "input size:  torch.Size([1, 10, 12, 12])\n",
      "output size:  torch.Size([1, 20, 8, 8])\n",
      "output norm:  13.748090078970105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def printnorm(self, input, output):\n",
    "    \"\"\"\n",
    "    In order to inspect / modify the output and grad_output of a layer,\n",
    "    we can use hook.\n",
    "    We can register a function on a Module or a Variable. \n",
    "    The hook can be a forward hook or a backward hook. \n",
    "    The forward hook will be executed when a forward call is executed.\n",
    "    The backward hook will be executed in the backward phase.\n",
    "    \"\"\"\n",
    "    # input is a tuple of packed inputs\n",
    "    # output is a Variable. output.data is the Tensor we are interested\n",
    "    print('Inside ' + self.__class__.__name__ + ' forward')\n",
    "    print('')\n",
    "    print('input: ', type(input))\n",
    "    print('input[0]: ', type(input[0]))\n",
    "    print('output: ', type(output))\n",
    "    print('')\n",
    "    print('input size: ', input[0].size())\n",
    "    print('output size: ', output.data.size())\n",
    "    print('output norm: ', output.data.norm())\n",
    "    print('')\n",
    "    \n",
    "net.conv2.register_forward_hook(printnorm)\n",
    "\n",
    "out = net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Conv2d forward\n",
      "\n",
      "input:  <class 'tuple'>\n",
      "input[0]:  <class 'torch.autograd.variable.Variable'>\n",
      "output:  <class 'torch.autograd.variable.Variable'>\n",
      "\n",
      "input size:  torch.Size([1, 10, 12, 12])\n",
      "output size:  torch.Size([1, 20, 8, 8])\n",
      "output norm:  13.748090078970105\n",
      "Inside Conv2d forward\n",
      "\n",
      "input:  <class 'tuple'>\n",
      "input[0]:  <class 'torch.autograd.variable.Variable'>\n",
      "output:  <class 'torch.autograd.variable.Variable'>\n",
      "\n",
      "Inside Conv2d backwardinput size: \n",
      " Inside class: Conv2dtorch.Size([1, 10, 12, 12])\n",
      "\n",
      "output size: \n",
      " grad_input: torch.Size([1, 20, 8, 8]) \n",
      "<class 'tuple'>output norm: \n",
      " grad_input[0]: 13.748090078970105 \n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "\n",
      "grad_output:  <class 'tuple'>\n",
      "grad_output[0]:  <class 'torch.autograd.variable.Variable'>\n",
      "\n",
      "grad_input size:  torch.Size([1, 10, 12, 12])\n",
      "grad_output size:  torch.Size([1, 20, 8, 8])\n",
      "grad_input norm:  0.09604130233119373\n",
      "Inside Conv2d backward\n",
      "Inside class: Conv2d\n",
      "\n",
      "grad_input:  <class 'tuple'>\n",
      "grad_input[0]:  <class 'torch.autograd.variable.Variable'>\n",
      "grad_output:  <class 'tuple'>\n",
      "grad_output[0]:  <class 'torch.autograd.variable.Variable'>\n",
      "\n",
      "grad_input size:  torch.Size([1, 10, 12, 12])\n",
      "grad_output size:  torch.Size([1, 20, 8, 8])\n",
      "grad_input norm:  0.09604130233119373\n",
      "\n",
      "Inside Conv2d backward\n",
      "Inside class: Conv2d\n",
      "\n",
      "grad_input:  <class 'tuple'>\n",
      "grad_input[0]:  <class 'torch.autograd.variable.Variable'>\n",
      "grad_output:  <class 'tuple'>\n",
      "grad_output[0]:  <class 'torch.autograd.variable.Variable'>\n",
      "\n",
      "grad_input size:  torch.Size([1, 10, 12, 12])\n",
      "grad_output size:  torch.Size([1, 20, 8, 8])\n",
      "grad_input norm:  0.09604130233119373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now register a backward hook on conv2 and print some information\n",
    "def printgradnorm(self, grad_input, grad_output):\n",
    "    print('Inside ' + self.__class__.__name__ + ' backward')\n",
    "    print('Inside class: ' + self.__class__.__name__)\n",
    "    print('')\n",
    "    print('grad_input: ', type(grad_input))\n",
    "    print('grad_input[0]: ', type(grad_input[0]))\n",
    "    print('grad_output: ', type(grad_output))\n",
    "    print('grad_output[0]: ', type(grad_output[0]))\n",
    "    print('')\n",
    "    print('grad_input size: ', grad_input[0].size())\n",
    "    print('grad_output size: ', grad_output[0].size())\n",
    "    print('grad_input norm: ', grad_input[0].data.norm())\n",
    "    print('')\n",
    "    \n",
    "net.conv2.register_backward_hook(printgradnorm)\n",
    "\n",
    "out = net(input)\n",
    "err = loss_fn(out, target)\n",
    "err.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Recurrent Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Since the state of the network is held in the graph and not in the layers,\n",
    "we can simply create an nn.Linear and reuse it over and over again for the recurrence.\n",
    "\"\"\"\n",
    "class RNN(nn.Module):\n",
    "    # you can also accept arguments in your model constructor\n",
    "    def __init__(self, data_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        input_size = data_size + hidden_size\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, data, last_hidden):\n",
    "        input = torch.cat((data, last_hidden), 1)\n",
    "        hidden = self.i2h(input)\n",
    "        output = self.h2o(hidden)\n",
    "        return hidden, output\n",
    "\n",
    "rnn = RNN(50, 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "batch_size = 10\n",
    "TIMESTEPS = 5\n",
    "\n",
    "# Create some fake data\n",
    "batch = Variable(torch.randn(batch_size, 50))\n",
    "hidden = Variable(torch.zeros(batch_size, 20))\n",
    "target = Variable(torch.zeros(batch_size, 10))\n",
    "\n",
    "loss = 0\n",
    "for t in range(TIMESTEPS):\n",
    "    # yes! you can reuse the same network several times,\n",
    "    # sum up the losses, and call backward!\n",
    "    hidden, output = rnn(batch, hidden)\n",
    "    loss += loss_fn(output, target)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
