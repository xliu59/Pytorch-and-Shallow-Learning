{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the image and labels\n",
    "images = np.load(\"./cs475_project_data/images.npy\")\n",
    "labels = np.load(\"./cs475_project_data/labels.npy\")\n",
    "num_imgs, height, width = images.shape\n",
    "images = images.reshape(num_imgs, height*width) # transform each image to a height*width dimension vector\n",
    "\n",
    "# separate out apple class\n",
    "X = torch.Tensor(images.copy().astype(float))\n",
    "Y = torch.Tensor(labels.copy().astype(float))\n",
    "is_apple = Y == 0\n",
    "not_apple = ~is_apple\n",
    "Y[is_apple] = 1 # label 1 for class 0 (apple), 10000 total\n",
    "Y[not_apple] = 0 # label 0 for other calsses (non-apple) ,  40000 total\n",
    "\n",
    "# separate training, cross-validation and testing data (40000:5000:5000)\n",
    "train_X, cross_X, test_X = X[:40000], X[40000:45000], X[45000:] # FloatTensors\n",
    "train_Y, cross_Y, test_Y = Y[:40000], Y[40000:45000], Y[45000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(object):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.w = None\n",
    "        self.lr = None\n",
    "        self.train_accu = None\n",
    "        self.cross_accu = None\n",
    "        self.w_arr = None\n",
    "        \n",
    "            \n",
    "    def predict_accuracy(self, X, Y, size):\n",
    "        rand_index = torch.LongTensor(np.random.randint(0, len(X), size))\n",
    "        X = Variable(X.index(rand_index), requires_grad=True)\n",
    "        Y = Variable(Y.index(rand_index), requires_grad=True)\n",
    "        Y_hat = self.predict(X)\n",
    "        accu = self.accuracy(Y, Y_hat)\n",
    "        return accu\n",
    "            \n",
    "        \n",
    "    def predict(self, X):\n",
    "        #print(\"in predict, X=\", type(X), X.data.shape, \",w=\", type(self.w), self.w.data.shape)\n",
    "        if self.w is None:\n",
    "            raise Exception('fit must be called before predict.')\n",
    "        \n",
    "        mean = torch.mean(X, 1) # mean of each row\n",
    "        X = (X - (mean.view(mean.size(0), 1))) / 255 # subtract mean and normalize to 1\n",
    "        \n",
    "        Y_hat = torch.sigmoid(X @ self.w)\n",
    "        Y_hat[Y_hat >= 0.5] = 1\n",
    "        Y_hat[Y_hat < 0.5] = 0\n",
    "        return Y_hat\n",
    "    \n",
    "    \n",
    "    def accuracy(self, y, y_hat):\n",
    "        \"\"\"Compute accuracy.\n",
    "        Args:\n",
    "           y: A 1-D int NumPy array.\n",
    "           y_hat: A 1-D int NumPy array.\n",
    "        Returns:\n",
    "           A float, the fraction of time y[i] == y_hat[i].\n",
    "        \"\"\"\n",
    "        return torch.mean((y == y_hat).float())   \n",
    "        \n",
    "        \n",
    "    def fit(self, X, Y, lr, num_iter):\n",
    "        self.lr = lr\n",
    "        X, Y = Variable(X, requires_grad=True), Variable(Y, requires_grad=True) # here X/Y is the train_X/Y dataset\n",
    "        num_examples, num_features = X.data.shape\n",
    "        w = Variable(torch.rand(num_features), requires_grad=True) # Variable of FloatTensor\n",
    "        \n",
    "        self.train_accu = []\n",
    "        self.cross_accu = []\n",
    "        self.w_arr = []\n",
    "        w_arr_id = 0\n",
    "        for k in range(num_iter):\n",
    "            running_loss = 0.0\n",
    "            for i in range(num_examples):\n",
    "                x = X[i] # 676/40000 * 676\n",
    "                y = Y[i] # 1/40000\n",
    "                \n",
    "                mean = torch.mean(x)\n",
    "                x = (x - mean) / 255\n",
    "                \n",
    "                #product = torch.clamp(w.dot(x), min = -88, max = 9)\n",
    "                product = w.dot(x)\n",
    "                loss = -y * torch.log(torch.sigmoid(product)) - (1 - y) * torch.log(1 - torch.sigmoid(product))\n",
    "                loss.backward()\n",
    "                w.data = w.data - lr * w.grad.data \n",
    "                w.grad.data.zero_()\n",
    "                \n",
    "                # print statistics\n",
    "                running_loss += loss.data[0]\n",
    "                if i % 100 == 99: \n",
    "                    self.w = w\n",
    "#                     print('[%d, %5d] loss: %.3f' % (k + 1, i + 1, running_loss/100))\n",
    "                        \n",
    "                    train_temp_accu = self.predict_accuracy(train_X, train_Y, 1000)\n",
    "#                     print(\"train_temp_accu= %.5f\" % train_temp_accu.data[0])\n",
    "                    self.train_accu.append(train_temp_accu.data[0])\n",
    "                    \n",
    "                    cross_temp_accu = self.predict_accuracy(cross_X, cross_Y, 1000)\n",
    "#                     print(\"cross_temp_accu= %.5f\" % cross_temp_accu.data[0])\n",
    "                    self.cross_accu.append(cross_temp_accu.data[0])\n",
    "                    \n",
    "                    \n",
    "#                     print(\"w_arr_id=\", w_arr_id)\n",
    "                    self.w_arr.append(w)\n",
    "                    w_arr_id += 1\n",
    "                    running_loss = 0.0\n",
    "#                     print(\"\")\n",
    "                    \n",
    "#                     plt.clf()\n",
    "#                     plt.plot(self.train_accu, 'r-')\n",
    "#                     plt.plot(self.cross_accu, 'b-')\n",
    "#                     plt.title(\"train(r) accuracy vs cross accuracy(b) - iteration\")\n",
    "#                     plt.show()\n",
    "            \n",
    "lgrg = LogisticRegression()\n",
    "lgrg.fit(train_X, train_Y, 0.1, 3)\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x117b78be0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot training accuracy as a function of iteration\n",
    "plt.plot(lgrg.train_accu, 'r-')\n",
    "\n",
    "# plot validation accuracy as a function of iteration\n",
    "plt.plot(lgrg.cross_accu, 'b-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Overfitting here?**\n",
    "\n",
    "A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
